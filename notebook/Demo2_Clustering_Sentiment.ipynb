{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1866fb4-e10a-42ba-9443-afeb97678930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all variables from the current environment\n",
    "locals().clear()\n",
    "globals().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69b1ebd-1e16-421b-aeb9-a0ace36002e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../input/business.pkl', 'rb') as f:\n",
    "    businesses = pickle.load(f)\n",
    "with open('../input/review.pkl', 'rb') as f:\n",
    "    all_reviews = pickle.load(f)\n",
    "\n",
    "# Cut the data size for reviews to 1000\n",
    "reviews = all_reviews.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda406a-ced0-4ff7-9524-453a21f5e650",
   "metadata": {},
   "source": [
    "Now we have filtered the businesses in Philadelphia, merges the reviews and businesses dataframes, performs sentiment analysis, and then performs KMeans clustering on the latitude, longitude, and sentiment values. The resulting clusters are visualized on a map and saved to an HTML file named \"clusters_map.html\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "769aa7ec-a67c-4aa2-9969-6494d48c6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/user.pkl', 'rb') as f:\n",
    "    users = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3ce02c0-7df0-49b8-b6b5-a056e2adf2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1987897 entries, 0 to 1987896\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   user_id             object \n",
      " 1   name                object \n",
      " 2   review_count        int64  \n",
      " 3   yelping_since       object \n",
      " 4   useful              int64  \n",
      " 5   funny               int64  \n",
      " 6   cool                int64  \n",
      " 7   elite               object \n",
      " 8   friends             object \n",
      " 9   fans                int64  \n",
      " 10  average_stars       float64\n",
      " 11  compliment_hot      int64  \n",
      " 12  compliment_more     int64  \n",
      " 13  compliment_profile  int64  \n",
      " 14  compliment_cute     int64  \n",
      " 15  compliment_list     int64  \n",
      " 16  compliment_note     int64  \n",
      " 17  compliment_plain    int64  \n",
      " 18  compliment_cool     int64  \n",
      " 19  compliment_funny    int64  \n",
      " 20  compliment_writer   int64  \n",
      " 21  compliment_photos   int64  \n",
      "dtypes: float64(1), int64(16), object(5)\n",
      "memory usage: 333.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(users.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf49df8-c0c0-4a25-aa7b-dc66156ffdca",
   "metadata": {},
   "source": [
    "To perform a geospatial analysis of user behavior, we can consider the number of reviews and average sentiment scores from users living in different regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67758bba-8f45-42ba-a976-9ea9616ca9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b30d5feb0b4c989d21add64b83e036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plotting markers:   0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from textblob import TextBlob\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# Merge dataframes\n",
    "reviews_users = pd.merge(reviews, users, on='user_id', how='inner')\n",
    "merged_data = pd.merge(reviews_users, businesses, on='business_id', how='inner')\n",
    "\n",
    "# Filter businesses in Philadelphia\n",
    "philadelphia_data = merged_data[merged_data['city'] == 'Philadelphia']\n",
    "\n",
    "# Function to visualize user behavior on a map\n",
    "def plot_user_behavior_on_map(df):\n",
    "    map = folium.Map(location=[39.952583, -75.165222], zoom_start=12)\n",
    "    marker_cluster = MarkerCluster()\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=df.shape[0], desc='Plotting markers'):\n",
    "        folium.Marker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            icon=None,\n",
    "            popup=f\"<b>Name:</b> {row['name_y']}<br><b>Stars:</b> {row['stars_x']}<br><b>Reviews:</b> {row['review_count_y']}<br><b>Address:</b> {row['address']}\"\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "    map.add_child(marker_cluster)\n",
    "    return map\n",
    "\n",
    "# Visualize the user behavior on a map\n",
    "user_behavior_map = plot_user_behavior_on_map(philadelphia_data)\n",
    "user_behavior_map.save(\"../result/user_behavior_map_demo.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb8159-024c-4c79-a1b1-d13fb6cee719",
   "metadata": {},
   "source": [
    "We merged the reviews, businesses, and users dataframes, performs sentiment analysis on the reviews, calculated the number of reviews and average sentiment scores for each user, normalized the number of reviews and average sentiment scores, and then visualized the user behavior on a map using a heatmap. The resulting map is saved to an HTML file named \"user_behavior_map.html\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bf7b432-8a35-42f1-a0a5-9537d96c1d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/cynthiali/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cynthiali/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/var/folders/gh/vymqxcwd2rn5wpkdmfjdh2g40000gn/T/ipykernel_11237/3929400547.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  philadelphia_data['top_keywords'] = philadelphia_data.groupby('user_id')['text'].transform(lambda texts: ', '.join(get_top_keywords(texts)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5cef2c08c340d58738dd6f8178ad84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plotting markers:   0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define a function to get the top N keywords\n",
    "def get_top_keywords(texts, n=10):\n",
    "    words = []\n",
    "    \n",
    "    # Define stopwords and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "\n",
    "    for text in texts:\n",
    "        # Tokenize and filter words\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        filtered_words = [word for word in tokens if word not in stop_words and word not in punctuation]\n",
    "        words.extend(filtered_words)\n",
    "    \n",
    "    # Count word occurrences\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Get the top N keywords\n",
    "    top_keywords = [item[0] for item in word_counts.most_common(n)]\n",
    "    \n",
    "    return top_keywords\n",
    "\n",
    "# Calculate the top N keywords for each user\n",
    "philadelphia_data['top_keywords'] = philadelphia_data.groupby('user_id')['text'].transform(lambda texts: ', '.join(get_top_keywords(texts)))\n",
    "\n",
    "# Add top N keywords to the map\n",
    "def plot_user_behavior_with_keywords_on_map(df):\n",
    "    map = folium.Map(location=[39.952583, -75.165222], zoom_start=12)\n",
    "    marker_cluster = MarkerCluster()\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=df.shape[0], desc='Plotting markers'):\n",
    "        folium.Marker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            icon=None,\n",
    "            popup=f\"<b>Name:</b> {row['name_y']}<br><b>Stars:</b> {row['stars_x']}<br><b>Reviews:</b> {row['review_count_y']}<br><b>Address:</b> {row['address']}<br><b>Keywords:</b> {row['top_keywords']}\"\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "    map.add_child(marker_cluster)\n",
    "    return map\n",
    "\n",
    "# Visualize the user behavior with keywords on a map\n",
    "user_behavior_map_with_keywords = plot_user_behavior_with_keywords_on_map(philadelphia_data)\n",
    "user_behavior_map_with_keywords.save(\"../result/user_behavior_map_with_keywords_demo.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13875fb3-1da6-4bbf-8b6f-8f19d87251f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
